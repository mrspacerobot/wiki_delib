{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "697c414c-af86-43e3-a6ae-133df6a9d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_cleaning\n",
    "import json\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import mwparserfromhell as mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38116672-25fb-495d-af60-83216526e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_parsed = \"../../data/json_files/grawitas_output/wikipedia_parsed.json\"\n",
    "wikidata_parsed = \"../../data/json_files/grawitas_output/wikidata_parsed.json\"\n",
    "meta_parsed = \"../../data/json_files/grawitas_output/meta_parsed.json\"\n",
    "with open(wikipedia_parsed) as f:\n",
    "        wikipedia_list_of_dicts = json.load(f)  \n",
    "\n",
    "with open(wikidata_parsed) as f:\n",
    "        wikidata_list_of_dicts = json.load(f) \n",
    "        \n",
    "with open(meta_parsed) as f:\n",
    "        meta_list_of_dicts = json.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c150ed13-c51d-4a86-bfd9-b673dfc5e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_comments, wiki_rfc = data_cleaning.get_RFC_Comment_Table(wikipedia_list_of_dicts, wikidata_list_of_dicts, meta_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ddd61c9-b4bd-40fb-986c-097150c6bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = pd.json_normalize(wiki_comments, \"page_text\", [\"page_title\",\"page_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfa3faae-8e6f-4e25-9779-cbdf2c99505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_df = pd.json_normalize(wiki_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "947ce3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/json_files/rfc_pages/meta.json\") as f:\n",
    "    meta = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d66d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in meta:\n",
    "    text = page['page_text']\n",
    "    wikicode = mw.parse(text)\n",
    "    rfc_templates = wikicode.filter_templates(matches=lambda template: template.name.matches(\"rfc subpage\"))\n",
    "    #comment_value = rfc_templates[0].get(\"comment\").value.strip()\n",
    "    if \"date\" in rfc_templates[0]:\n",
    "        date_value = rfc_templates[0].get(\"date\").value.strip()\n",
    "        rfc_df.loc[rfc_df['page_id'] == page['page_id'], 'closing_date'] = date_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d0218868",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/json_files/rfc_pages/wikidata.json\") as f:\n",
    "    wikidata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c5e15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "for page in wikidata:\n",
    "    text = wikidata[0]['page_text']\n",
    "    wikicode = mw.parse(text)\n",
    "    rfc_templates = wikicode.filter_templates(matches=lambda template: template.name.matches(\"discussion top\"))\n",
    "    #comment_value = rfc_templates[0].get(\"comment\").value.strip()\n",
    "    text = rfc_templates[0].params[0]\n",
    "    date = re.search(r'\\d{2}:\\d{2}, \\d{1,2} \\w+ \\d{4} \\(UTC\\)', str(text))\n",
    "    # parse the input string into a datetime object\n",
    "    input_datetime = datetime.strptime(date.group(), \"%H:%M, %d %B %Y (%Z)\")\n",
    "\n",
    "    # format the datetime object in the desired output format\n",
    "    output_str = input_datetime.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    if output_str:\n",
    "        rfc_df.loc[rfc_df['page_id'] == page['page_id'], 'closing_date'] = output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac8de440",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/json_files/rfc_pages/wikipedia.json\") as f:\n",
    "    wikipedia = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b664042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "for page in wikipedia:\n",
    "    text = page['page_text']\n",
    "    wikicode = mw.parse(text)\n",
    "    rfc_templates = wikicode.filter_templates(matches=lambda template: template.name.matches(\"closed rfc top\"))\n",
    "    #comment_value = rfc_templates[0].get(\"comment\").value.strip()\n",
    "    if not rfc_templates:\n",
    "        continue\n",
    "    if not rfc_templates[0].params:\n",
    "        continue\n",
    "    text = rfc_templates[0].params[0]\n",
    "    date = re.search(r'\\d{2}:\\d{2}, \\d{1,2} \\w+ \\d{4} \\(UTC\\)', str(text))\n",
    "    # parse the input string into a datetime object\n",
    "    if not date:\n",
    "        continue\n",
    "    input_datetime = datetime.strptime(date.group(), \"%H:%M, %d %B %Y (%Z)\")\n",
    "\n",
    "    # format the datetime object in the desired output format\n",
    "    output_str = input_datetime.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    if output_str:\n",
    "        rfc_df.loc[rfc_df['page_id'] == page['page_id'], 'closing_date'] = output_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3d4cc86e-7e73-4216-8309-daf8ca9ed8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102474/102474 [01:48<00:00, 940.44it/s] \n"
     ]
    }
   ],
   "source": [
    "data_cleaning.templatesToReadableText(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "af0b7b98-273d-47cf-ae92-6f1043e165ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectLanguage(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "        url = re.findall(regex, text)\n",
    "        if url:\n",
    "            return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7260b80d-c3f6-475e-8758-bb27a8ce660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14159/3506980960.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  comment_df['text'] = comment_df['text'].str.replace(pattern, '')\n"
     ]
    }
   ],
   "source": [
    "# define regular expression pattern for matching non-word characters\n",
    "non_word_pattern = re.compile(r'^\\W*$')\n",
    "\n",
    "non_alpha_pattern = re.compile(r'^[^a-zA-Z]+$')\n",
    "\n",
    "# Define regex pattern\n",
    "pattern = \"\\s*15px(?:\\|[a-zA-Z]+=\\s*)?(?:\\|[a-zA-Z]+=)?(?:\\|[a-zA-Z]+\\s*)?\"\n",
    "\n",
    "comment_df['text'] = comment_df['text'].str.replace(pattern, '')\n",
    "\n",
    "# filter dataframe to remove rows that contain only non-alpha characters\n",
    "comment_df = comment_df[~comment_df['text'].str.contains(non_alpha_pattern)]\n",
    "\n",
    "# filter dataframe to remove rows that contain only non-word characters\n",
    "comment_df = comment_df[~comment_df['text'].str.contains(non_word_pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad26fb85-1afb-490a-a2ce-aca1424e3142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101449/101449 [13:50<00:00, 122.13it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "# Add a new column to the DataFrame indicating the language of the text\n",
    "comment_df['language'] = comment_df['text'].progress_apply(detectLanguage)\n",
    "\n",
    "comment_df = comment_df[comment_df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "456c5be2-7a97-4d89-af1a-b11c5c109594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "gfg_csv_data = rfc_df.to_csv('../../data/rfc.csv', index = False)\n",
    "print('\\nCSV String:\\n', gfg_csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "19e771c9-55d4-4d24-b311-4f5d600bedae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#comment_df.loc[60187,'date'] = '2022-03-22T23:36:00Z'\n",
    "gfg_csv_data = comment_df.to_csv('../../data/rfc_comments.csv', index = False)\n",
    "print('\\nCSV String:\\n', gfg_csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cb016f9-9e39-4002-8351-16243a86382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = pd.read_csv('../../data/rfc_comments.csv')\n",
    "def getcleanDataFrame(df):\n",
    "    #remove IP-Adresses from userArray\n",
    "    df = df[~df['user'].str.contains(re.compile(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b'))]\n",
    "    return list(df[\"user\"].unique())\n",
    "\n",
    "user_list = getcleanDataFrame(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3e4b62c5-e9f4-4f61-bf84-bceb9dbfa45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9265\n"
     ]
    }
   ],
   "source": [
    "print(len(user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "524995d9-c828-4c78-8c40-bce801869397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9265it [3:14:14,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "from userinformation import getUserInfoToJSON\n",
    "getUserInfoToJSON(user_list, \"../../data/json_files/user_info/users.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0dafd10a-80b8-416b-92ab-01120826d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by project type and rfc_id\n",
    "grouped = comment_df.groupby(['project', 'rfc_id'])\n",
    "\n",
    "# Define a function to remove the first 2 comments per different rfc_id\n",
    "def remove_comments(group):\n",
    "    if len(group) > 2:\n",
    "        return group.iloc[2:]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Apply the function to each group and concatenate the results\n",
    "filtered = grouped.apply(remove_comments).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bf9b14d-eada-49b8-a981-290eb9c5e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by class and sample 65 rows from each group\n",
    "df_labelling = filtered.groupby('project').apply(lambda x: x.sample(65)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65021394-5b23-4769-bb27-e7918822905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate URLs based on page IDs\n",
    "def get_wikipedia_url(row):\n",
    "    page_id = row['page_id']\n",
    "    project = row['project']\n",
    "    return f'https://{project}.org/wiki?curid={page_id}'\n",
    "\n",
    "# Apply the function to the page_id column and assign the result to a new column\n",
    "df_labelling['page_url'] = df_labelling.apply(get_wikipedia_url, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f27755cb-df48-4493-9535-a985264b4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings to add as new columns\n",
    "new_cols = [ 'disrespect','respect','explanation','causal_reasoning','narrative', 'question', 'response', 'advocacy', 'public_interest','counterarguments', 'constructive_proposal']\n",
    "\n",
    "# Add the new columns to the DataFrame\n",
    "for col in new_cols:\n",
    "    df_labelling[col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0490176b-ad05-4e47-9c7e-57a4b2fe3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labelling = df_labelling.drop([\"date\",\"section\",\"page_id\", \"rfc_id\", \"parent_id\", \"language\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3dc13718-3144-456e-a47f-d0dd1dc0c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "gfg_csv_data = df_labelling.to_csv('label_rfc_statements.csv', index = False)\n",
    "print('\\nCSV String:\\n', gfg_csv_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
