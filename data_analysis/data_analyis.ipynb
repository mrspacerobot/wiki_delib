{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f0488-53f5-458a-9d4d-246fe508985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install shifterator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a605c-aac7-4a55-8d0c-01672af094fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_df = pd.read_csv('rfc.csv')\n",
    "df = pd.read_csv('rfc_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d7682-f183-4ac1-9c42-a0271730d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# extract the year from date column and create a new column\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# count the number of comments per year and create a new dataframe\n",
    "count_df = df.groupby('year').size().reset_index(name='counts')\n",
    "\n",
    "# plot the count dataframe\n",
    "plt.plot(count_df['year'], count_df['counts'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.title('Comments per Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44011722-8b54-4464-b3c3-654df2153588",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_json = \"../json_files/user_info/users.json\"\n",
    "with open(user_json) as f:\n",
    "    users = json.load(f)\n",
    "users_df = pd.DataFrame(users)\n",
    "print(len(users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3342ec-e27b-407b-b714-9d8d4cad6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users_df[users_df['editcount'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac940c-00c3-4ddb-9157-7e06648c2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of wikis to include\n",
    "wikis_to_include = ['enwiki','eswiki','frwiki','dewiki','zhwiki','jawiki','plwiki','ruwiki','itwiki','nlwiki','ptwiki']\n",
    "\n",
    "# create new column with sum of edit counts for desired wikis\n",
    "def sum_edit_counts(edit_count_dict, wikis_to_include):\n",
    "    try:\n",
    "        if edit_count_dict:\n",
    "            edit_count_dict['wikipedia_project_sum'] = sum(edit_count_dict[wiki] for wiki in wikis_to_include)\n",
    "            return edit_count_dict\n",
    "        else:\n",
    "            return edit_count_dict\n",
    "    except KeyError:\n",
    "        print(edit_count_dic)\n",
    "\n",
    "users_df['editcount'] = users_df['editcount'].apply(lambda x: sum_edit_counts(x, wikis_to_include))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56cd26a-2985-4e97-ba10-bf54af2fb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with any NA values\n",
    "df = users_df.dropna()\n",
    "# projects to calculate median edit count for\n",
    "projects = ['metawiki', 'wikidatawiki', 'wikipedia_project_sum']\n",
    "\n",
    "# create list of edit counts for each project\n",
    "edit_counts = [[d.get(p, 0) for d in df['editcount']] for p in projects]\n",
    "\n",
    "# calculate median edit count for each project\n",
    "median_edit_counts = [pd.Series(ec).median() for ec in edit_counts]\n",
    "for i, p in enumerate(projects):\n",
    "    print(f\"The median edit count for {p} is {median_edit_counts[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b27e9-a6bf-44c4-8fe1-afd1fdbe173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert registration_date to datetime object\n",
    "users_df['user_registration'] = pd.to_datetime(users_df['user_registration'])\n",
    "\n",
    "# calculate account age\n",
    "users_df['account_age'] = (datetime.now() - users_df['user_registration']).dt.days\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2cbeb-0494-45e8-9f91-7606aada88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "# convert registration_date to datetime object\n",
    "users_df['user_registration'] = pd.to_datetime(users_df['user_registration'])\n",
    "\n",
    "# calculate account age\n",
    "users_df['account_age'] = (datetime.now() - users_df['user_registration']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f07575-54dc-477e-baf8-c1651abcd185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = users_df.dropna()\n",
    "# create a list of all unique dictionary keys in the permissions column\n",
    "all_keys = set().union(*df['permissions'].apply(dict.keys).tolist())\n",
    "\n",
    "# create a dictionary with all unique values for each key\n",
    "all_values = {}\n",
    "for key in all_keys:\n",
    "    values = set()\n",
    "    for d in df['permissions']:\n",
    "        if key in d:\n",
    "            values.add(d[key])\n",
    "    all_values[key] = list(values)\n",
    "\n",
    "# print the unique values for each key\n",
    "for key, values in all_values.items():\n",
    "    print(f'{key}: {values}')\n",
    "# create a function to get the key for a given value\n",
    "def get_permission_key(d, value):\n",
    "    for key, val in d.items():\n",
    "        if val == value:\n",
    "            return True\n",
    "    return None\n",
    "\n",
    "# create a new column for each value and assign the corresponding key\n",
    "df['user_permission'] = df['permissions'].apply(lambda x: get_permission_key(x, 'user'))\n",
    "df['sysop_permission'] = df['permissions'].apply(lambda x: get_permission_key(x, 'sysop'))\n",
    "df['bureaucrat_permission'] = df['permissions'].apply(lambda x: get_permission_key(x, 'bureaucrat'))\n",
    "df['bot_permission'] = df['permissions'].apply(lambda x: get_permission_key(x, 'bot'))\n",
    "\n",
    "# preview the updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174da345-5456-45d4-8e68-85f1b8a4fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows where sysop permission is present\n",
    "num_sysop_rows = df['sysop_permission'].notnull().sum()\n",
    "\n",
    "# print the result\n",
    "print(f\"Number of rows with sysop permission: {num_sysop_rows}\")\n",
    "# count the number of rows where sysop permission is present\n",
    "num_sysop_rows = df['user_permission'].notnull().sum()\n",
    "\n",
    "# print the result\n",
    "print(f\"Number of rows with sysop permission: {num_sysop_rows}\")\n",
    "# count the number of rows where sysop permission is present\n",
    "num_sysop_rows = df['bureaucrat_permission'].notnull().sum()\n",
    "\n",
    "# print the result\n",
    "print(f\"Number of rows with sysop permission: {num_sysop_rows}\")\n",
    "# count the number of rows where sysop permission is present\n",
    "num_sysop_rows = df['bot_permission'].notnull().sum()\n",
    "\n",
    "# print the result\n",
    "print(f\"Number of rows with sysop permission: {num_sysop_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ebb68-b564-450f-9302-649354274446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rfc_comments.csv')\n",
    "grouped = df.groupby('project')\n",
    "# create a dictionary of dataframes, with one dataframe for each unique value in the \"class\" column\n",
    "dfs = {name: group for name, group in grouped}\n",
    "\n",
    "# access each dataframe using its corresponding key\n",
    "df_wikipedia_text = dfs['wikipedia']['text'].tolist()\n",
    "df_wikidata_text = dfs['wikidata']['text'].tolist()\n",
    "df_meta_text = dfs['meta.wikimedia']['text'].tolist()\n",
    "# download the stopwords data if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# get the set of English stopwords\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00fafe-388f-445e-aa94-325f91b8950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(txt):\n",
    "    \"\"\"Replace URLs and other punctuation found in a text string with nothing \n",
    "    (i.e. it will remove the URL from the string).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : string\n",
    "        A text string that you want to parse and remove urls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The same txt string with URLs and punctuation removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "def clean_text(txt):\n",
    "    \"\"\"Removes punctuation, changes to lowercase, removes\n",
    "        stopwords, removes \"animal\" and \"crossing\", and\n",
    "        calculates word frequencies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : string\n",
    "        A text string that you want to clean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Words and frequencies\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp = [remove_punctuation(t) for t in txt]\n",
    "    tmp = [t.lower().split() for t in tmp]\n",
    "    \n",
    "    tmp = [[w for w in t if not w in stop_words]\n",
    "              for t in tmp]\n",
    "    tmp = [[w for w in t if not w in ['animal', 'crossing']]\n",
    "                     for t in tmp]\n",
    "    \n",
    "    tmp = list(itertools.chain(*tmp))\n",
    "    tmp = collections.Counter(tmp)\n",
    "        \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b44ae5-293e-4e96-8b43-2457df011273",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts_wikipedia = clean_text(df_wikipedia_text)\n",
    "clean_texts_wikidata = clean_text(df_wikidata_text)\n",
    "clean_texts_meta = clean_text(df_meta_text)\n",
    "from shifterator import shifts as rs\n",
    "entropy_shift = rs.EntropyShift(clean_texts_wikipedia, clean_texts_wikidata, base = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
