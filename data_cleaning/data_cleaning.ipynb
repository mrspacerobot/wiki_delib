{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697c414c-af86-43e3-a6ae-133df6a9d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /srv/paws/lib/python3.10/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /srv/paws/lib/python3.10/site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import data_cleaning\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "!{sys.executable} -m pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38116672-25fb-495d-af60-83216526e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_parsed = \"../json_files/grawitas_output/wikipedia_parsed.json\"\n",
    "wikidata_parsed = \"../json_files/grawitas_output/wikidata_parsed.json\"\n",
    "meta_parsed = \"../json_files/grawitas_output/meta_parsed.json\"\n",
    "with open(wikipedia_parsed) as f:\n",
    "        wikipedia_list_of_dicts = json.load(f)  \n",
    "\n",
    "with open(wikidata_parsed) as f:\n",
    "        wikidata_list_of_dicts = json.load(f) \n",
    "        \n",
    "with open(meta_parsed) as f:\n",
    "        meta_list_of_dicts = json.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150ed13-c51d-4a86-bfd9-b673dfc5e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_comments, wiki_rfc = data_cleaning.get_RFC_Comment_Table(wikipedia_list_of_dicts, wikidata_list_of_dicts, meta_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd61c9-b4bd-40fb-986c-097150c6bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = pd.json_normalize(wiki_comments, \"page_text\", [\"page_title\",\"page_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3faae-8e6f-4e25-9779-cbdf2c99505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_df = pd.json_normalize(wiki_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cc86e-7e73-4216-8309-daf8ca9ed8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning.templatesToReadableText(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b7b98-273d-47cf-ae92-6f1043e165ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import re\n",
    "def detectLanguage(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "        url = re.findall(regex, text)\n",
    "        if url:\n",
    "            return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c50d5-e7da-429b-acdb-ac9dac804bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regular expression pattern for matching non-word characters\n",
    "non_word_pattern = re.compile(r'^\\W*$')\n",
    "\n",
    "non_alpha_pattern = re.compile(r'^[^a-zA-Z]+$')\n",
    "\n",
    "# Define regex pattern\n",
    "pattern = '\\s*15px\\|[a-zA-Z]+=\\s*\\|[a-zA-Z]+=[a-zA-Z]+\\s*\\|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26fb85-1afb-490a-a2ce-aca1424e3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "comment_df['text'] = comment_df['text'].str.replace(pattern, '')\n",
    "\n",
    "# filter dataframe to remove rows that contain only non-alpha characters\n",
    "comment_df = comment_df[~comment_df['text'].str.contains(non_alpha_pattern)]\n",
    "\n",
    "# filter dataframe to remove rows that contain only non-word characters\n",
    "comment_df = comment_df[~comment_df['text'].str.contains(non_word_pattern)]\n",
    "\n",
    "# Add a new column to the DataFrame indicating the language of the text\n",
    "comment_df['language'] = comment_df['text'].progress_apply(detectLanguage)\n",
    "\n",
    "comment_df = comment_df[comment_df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c5be2-7a97-4d89-af1a-b11c5c109594",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfg_csv_data = rfc_df.to_csv('rfc.csv', index = False)\n",
    "print('\\nCSV String:\\n', gfg_csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19e771c9-55d4-4d24-b311-4f5d600bedae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "comment_df.loc[60187,'date'] = '2022-03-22T23:36:00Z'\n",
    "gfg_csv_data = comment_df.to_csv('rfc_comments.csv', index = False)\n",
    "print('\\nCSV String:\\n', gfg_csv_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb016f9-9e39-4002-8351-16243a86382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcleanDataFrame(df):\n",
    "    #remove IP-Adresses from userArray\n",
    "    df = df[~df['user'].str.contains(re.compile(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b'))]\n",
    "    return list(df[\"user\"].unique())\n",
    "\n",
    "user_list = getcleanDataFrame(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4b62c5-e9f4-4f61-bf84-bceb9dbfa45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9314\n"
     ]
    }
   ],
   "source": [
    "print(len(user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524995d9-c828-4c78-8c40-bce801869397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5567it [1:21:15,  2.83it/s]"
     ]
    }
   ],
   "source": [
    "from userinformation import getUserInfoToJSON\n",
    "getUserInfoToJSON(user_list, \"../json_files/user_info/users.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853728e3-5c4c-4b5f-9776-4abafecf0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserInfoToJSON(userArray, output):\n",
    "    \"\"\"\n",
    "    Takes list of users outputs list of JSON objects containing wiki projects, user rights, edit count, registration and first comment dates\n",
    "    \"\"\" \n",
    "    with multiprocessing.Pool(processes=8) as pool:\n",
    "        results = list(tqdm.tqdm(pool.imap(worker, userArray)))\n",
    "        with open(output, 'w') as file:\n",
    "            json.dump(list(results), file)\n",
    "    \n",
    "    \n",
    "def worker(user):\n",
    "    try:\n",
    "        userDic = getUserInfoAcrossAllReplicaDatabases(user)\n",
    "        return userDic\n",
    "    except:\n",
    "        print(f\"failed to get userDic, with {user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dafd10a-80b8-416b-92ab-01120826d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = pd.read_csv('rfc_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf9b14d-eada-49b8-a981-290eb9c5e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by class and sample 65 rows from each group\n",
    "df_labelling = comment_df.groupby('project').apply(lambda x: x.sample(65)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65021394-5b23-4769-bb27-e7918822905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate URLs based on page IDs\n",
    "def get_wikipedia_url(row):\n",
    "    page_id = row['page_id']\n",
    "    project = row['project']\n",
    "    return f'https://{project}.org/wiki?curid={page_id}'\n",
    "\n",
    "# Apply the function to the page_id column and assign the result to a new column\n",
    "df_labelling['page_url'] = df_labelling.apply(get_wikipedia_url, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f27755cb-df48-4493-9535-a985264b4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings to add as new columns\n",
    "new_cols = [ 'disrespect','respect','explanation','causal_reasoning','narrative', 'question', 'response', 'advocacy', 'public_interest','counterarguments', 'constructive_proposal']\n",
    "\n",
    "# Add the new columns to the DataFrame\n",
    "for col in new_cols:\n",
    "    df_labelling[col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0490176b-ad05-4e47-9c7e-57a4b2fe3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labelling = df_labelling.drop([\"date\",\"section\",\"page_id\", \"rfc_id\", \"parent_id\", \"language\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dc13718-3144-456e-a47f-d0dd1dc0c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "gfg_csv_data = df_labelling.to_csv('label_rfc_statements.csv', index = False)\n",
    "print('\\nCSV String:\\n', gfg_csv_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
