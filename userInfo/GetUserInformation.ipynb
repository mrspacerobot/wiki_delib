{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b075499-e608-4222-b8e9-3f7b8dba5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##With preprocessed RFC-Discussion getting Information on Users\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "wikipedia_parsed = \"../json_files/grawitas_output/wikipedia_parsed.json\"\n",
    "wikidata_parsed = \"../json_files/grawitas_output/wikidata_parsed.json\"\n",
    "meta_parsed = \"../json_files/grawitas_output/meta_parsed.json\"\n",
    "with open(wikipedia_parsed) as f:\n",
    "        wikipedia_list_of_dicts = json.load(f)\n",
    "with open(wikidata_parsed) as f:\n",
    "        wikidata_list_of_dicts = json.load(f)\n",
    "with open(meta_parsed) as f:\n",
    "        meta_list_of_dicts = json.load(f)\n",
    "        \n",
    "def getcleanDataFrame(json):\n",
    "    df = pd.json_normalize(json, \"page_text\", [\"page_title\"])\n",
    "    #remove IP-Adresses from userArray\n",
    "    df2 = df[~df['user'].str.contains(re.compile(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b'))]\n",
    "    return list(df2[\"user\"].unique())\n",
    "\n",
    "\n",
    "wikipedia_user_list = getcleanDataFrame(wikipedia_list_of_dicts)\n",
    "wikidata_user_list = getcleanDataFrame(wikidata_list_of_dicts)\n",
    "meta_user_list = getcleanDataFrame(wikidata_list_of_dicts)\n",
    "\n",
    "# Concatenate the lists\n",
    "merged_user_list = wikipedia_user_list + wikidata_user_list + meta_user_list\n",
    "\n",
    "# Convert to a set to remove duplicates\n",
    "unique_user_list = list(set(merged_user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0ea2c7-5b36-4143-9bd5-91da2f7e3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8097\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a90cbb3-b3f3-462a-a602-8bc8ef97ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' userinformation.py '''\n",
    "#Functions for getting data from MongoDB across different projects\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import date, timedelta,datetime\n",
    "import multiprocessing\n",
    "import tqdm\n",
    "\n",
    "def make_connection(wiki, replica_type=\"analytics\"):\n",
    "    \"\"\"Connects to a host and database of the same name.\n",
    "    \n",
    "    `replica_type` can be either \"analytics\" (default), or \"web\".\"\"\"\n",
    "    assert replica_type == \"web\" or replica_type == \"analytics\"\n",
    "    return pymysql.connect(\n",
    "        host=f\"{wiki}.{replica_type}.db.svc.wikimedia.cloud\",\n",
    "        read_default_file=\"../.my.cnf\",\n",
    "        database=f\"{wiki}_p\",\n",
    "        charset='utf8'\n",
    "    )\n",
    "\n",
    "def query(conn, query):\n",
    "    \"\"\"Execute a SQL query against the connection, and return **all** the results.\"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        data = cur.fetchall()\n",
    "        return data\n",
    "    \n",
    "def getActorID(username, wiki):\n",
    "    commons_conn = make_connection(f'{wiki}')\n",
    "    sql_string = f\"SELECT * FROM actor WHERE actor_name='{username}'\"\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        sql_string\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def getUserID(username, wiki):\n",
    "    commons_conn = make_connection(f'{wiki}')\n",
    "    sql_string = f\"SELECT user_id FROM user WHERE user_name='{username}'\"\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        sql_string\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getFirstActorCommentDate(actorID,wiki):\n",
    "    commons_conn = make_connection(f\"{wiki}\")\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        f\"SELECT MIN(rev_timestamp) FROM revision INNER JOIN comment ON revision.rev_comment_id=comment.comment_id WHERE rev_actor='{actorID}';\"\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getUserRegistrationDate(user_name,wiki):\n",
    "    \n",
    "    commons_conn = make_connection(f\"{wiki}\")\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        f\"SELECT user_registration FROM user WHERE user_name='{user_name}';\"\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def getUserInformation(user_name, wiki_list):\n",
    "    #getting base user information from mediawiki \n",
    "    commons_conn = make_connection(\"mediawikiwiki\")\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        f\"SELECT user_id,user_name,user_real_name, user_registration, user_editcount FROM user WHERE user_name='{user_name}';\"\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    \n",
    "    if results:\n",
    "        userDic = {'user_id' : results[0][0], 'user_name' : results[0][1].decode(\"utf-8\"),'user_real_name' : results[0][2].decode(\"utf-8\")}\n",
    "    else:\n",
    "        userDic = {'user_id' : None, 'user_name' : user_name, 'user_real_name' : None}\n",
    "    \n",
    "    \n",
    "    #looping through all wiki projects, getting user rights, edit count, registration and first comment dates\n",
    "    wiki_editcount_dic = {}\n",
    "    wiki_permissions_dic = {}\n",
    "    first_comment_date_list = []\n",
    "    registration_date = []\n",
    "    \n",
    "    for wiki in wiki_list:\n",
    "        wiki_editcount_dic[wiki] = getUserEditCount(user_name, wiki)\n",
    "        id = getUserID(user_name,wiki)\n",
    "        wiki_permissions_dic[wiki] = getUserGroups(id, wiki)\n",
    "        first_comment_date = getFirstActorCommentDate(getActorID(user_name,wiki),wiki)\n",
    "        regis_date = getUserRegistrationDate(user_name,wiki)\n",
    "        if first_comment_date:\n",
    "            first_comment_date_list.append(first_comment_date)\n",
    "        if regis_date:\n",
    "            registration_date.append(regis_date)\n",
    "    #user does not exist in any project database anymore\n",
    "    if not registration_date:\n",
    "        userDic['isDeleted'] = True\n",
    "        userDic['user_registration'] = None\n",
    "        userDic['seconds_between_regdate_and_first_edit_date'] = None\n",
    "        userDic['editcount'] = None\n",
    "        userDic['permissions'] = None\n",
    "    else:\n",
    "        registration = datetime.strptime(min(registration_date).decode(\"utf-8\"), \"%Y%m%d%H%M%S\")\n",
    "        \n",
    "        if first_comment_date_list:\n",
    "            first_comment = datetime.strptime(min(first_comment_date_list).decode(\"utf-8\"), \"%Y%m%d%H%M%S\")\n",
    "            #calc time between registration and first comment\n",
    "            delta = first_comment - registration\n",
    "            userDic['seconds_between_regdate_and_first_edit_date'] = delta.total_seconds()\n",
    "        #user never made a revision\n",
    "        else:\n",
    "            first_comment = None\n",
    "            userDic['seconds_between_regdate_and_first_edit_date'] = None\n",
    "        \n",
    "        #setting values for user inf\n",
    "        userDic['isDeleted'] = False\n",
    "        userDic['user_registration'] = registration.isoformat()\n",
    "        userDic['editcount'] = wiki_editcount_dic\n",
    "        userDic['permissions'] = wiki_permissions_dic\n",
    "    return userDic\n",
    "\n",
    "def getUserEditCount(user_name, wiki):\n",
    "    actor_id = getActorID(user_name, wiki)\n",
    "    commons_conn = make_connection(f\"{wiki}\")\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        f\"SELECT COUNT(*) FROM revision WHERE rev_actor = '{actor_id}';\"\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def getUserInfoAcrossAllReplicaDatabases(user):\n",
    "    #not going over all wikis too much data\n",
    "    '''\n",
    "    commons_conn = make_connection(\"meta\")\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        'SELECT dbname, url, is_closed from wiki;'\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    replica_databases = pd.DataFrame(results)\n",
    "    replica_databases.head()\n",
    "    replica_databases_list = replica_databases[0].tolist()\n",
    "    '''\n",
    "    #prepare username for sql\n",
    "    escaped_string = user.replace(\"'\", \"''\")\n",
    "    escaped_string2 = escaped_string.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "    wiki_list = ['mediawikiwiki','metawiki','wikidatawiki', 'enwiki','eswiki','frwiki','dewiki','zhwiki','jawiki','plwiki','ruwiki','itwiki','nlwiki', 'ptwiki']\n",
    "    return getUserInformation(escaped_string2,wiki_list)\n",
    "\n",
    "def getUserGroups(user_id, wiki):\n",
    "    commons_conn = make_connection(f\"{wiki}\")\n",
    "    results = query(\n",
    "        commons_conn,\n",
    "        f\"SELECT ug_group FROM user_groups WHERE ug_user='{user_id}';\"\n",
    "    )\n",
    "    commons_conn.close()\n",
    "    #returns bot, burocrat, sysop \n",
    "    if results:\n",
    "        return results[0][0].decode(\"utf-8\")\n",
    "    else:\n",
    "        return \"user\"\n",
    "    \n",
    "\n",
    "def getUserInfoToJSON(userArray, output):\n",
    "    \"\"\"\n",
    "    Takes list of users outputs list of JSON objects containing wiki projects, user rights, edit count, registration and first comment dates\n",
    "    \"\"\" \n",
    "    with multiprocessing.Pool(processes=8) as pool:\n",
    "        results = pool.map_async(worker, userArray)\n",
    "        with open(output, 'w') as file:\n",
    "            json.dump(list(results), file)\n",
    "    \n",
    "    \n",
    "def worker(user):\n",
    "    try:\n",
    "        userDic = getUserInfoAcrossAllReplicaDatabases(user)\n",
    "        return userDic\n",
    "    except:\n",
    "        print(f\"failed to get userDic, with {user}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b10560-d720-4efd-9e66-39e08e14065e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgetUserInfoToJSON\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mArkanosis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTangoFett\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../json_files/user_info/users.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 190\u001b[0m, in \u001b[0;36mgetUserInfoToJSON\u001b[0;34m(userArray, output)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mTakes list of users outputs list of JSON objects containing wiki projects, user rights, edit count, registration and first comment dates\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 190\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserArray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    192\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;28mlist\u001b[39m(results), file)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "getUserInfoToJSON(['Arkanosis', 'TangoFett'], \"../json_files/user_info/users.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd67b3-843f-46e5-bb18-ea69ac55414a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1ef3b-6c26-4d35-ba84-e8140f816ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = \"../json_files/user_info/users.json\"\n",
    "with open(users) as f:\n",
    "        user_list_of_dicts = json.load(f)\n",
    "df = pd.json_normalize(user_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db03da-c98e-4a01-834a-dfe66f62600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
